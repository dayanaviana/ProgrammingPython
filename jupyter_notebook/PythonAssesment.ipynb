{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load program\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "html_page = urllib.request.urlopen('https://www.census.gov/programs-surveys/popest.html').read()\n",
    "soup = BeautifulSoup(html_page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n<html lang=\"en\" xml:lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\">\n <head>\n  <!--[if lt IE 9]><meta http-equiv=\"X-UA-Compatible\" content=\"IE=EmulateIE8\"  /><![endif]-->\n  <!--[if gte IE 9]><meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <![endif]-->\n  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n  <link href=\"/etc/designs/census/bootstrap.css\" rel=\"styleshe\n"
    }
   ],
   "source": [
    "print(soup.prettify()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "13.4 ms ± 1.7 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "92"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "links_dic =  {}\n",
    "def loadLinks_fromDic():\n",
    "    file = open(\"my_web_links3.csv\", \"w\")\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\"^http\")}):\n",
    "        soup_link = str(link['href'])\n",
    "        soup_link = re.split(\"//\", soup_link,1)[1] \n",
    "        index_code = hash(soup_link)\n",
    "        links_dic[index_code] = soup_link\n",
    "    for i in links_dic:\n",
    "        file.write(links_dic[i] + \"\\n\")\n",
    "    file.flush()    \n",
    "    file.close()\n",
    "%timeit loadLinks_fromDic()\n",
    "len(links_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "36 ms ± 3.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "92"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "#Sets are significantly faster when it comes to determining if an object is present in the set (as in x in s), but are slower than lists when it comes to iterating over their contents.\n",
    "def loadLinks_setDt():\n",
    "    file = open(\"my_web_links1.csv\", \"w\")\n",
    "    links_set =  set()\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\"^http\")}):\n",
    "        soup_link = str(link['href'])\n",
    "        soup_link = re.split(\"//\", soup_link,1)[1] \n",
    "        links_set.add(soup_link)\n",
    "    for i in links_set:\n",
    "        file.write(i + \"\\n\")\n",
    "    file.flush()    \n",
    "    file.close()\n",
    "%timeit loadLinks_setDt()\n",
    "len(links_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "233 ms ± 10.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "92"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "def loadLinks_byIndex():\n",
    "    links_series = pd.Series()\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\"^http\")}):\n",
    "        soup_link = str(link['href'])\n",
    "        #Split the string only at the first occurrence\n",
    "        soup_link = re.split(\"//\", soup_link,1)[1]\n",
    "        index_code = str(hash(soup_link))\n",
    "        links_series[index_code] = soup_link\n",
    "    #csv files should always be opened in binary mode\n",
    "    # csv line terminator: \\r\\n\n",
    "    file = open(\"my_web_links2.csv\", \"w\", newline='')\n",
    "    file.write(links_series.to_csv(index=False, header=False))\n",
    "    file.flush()    \n",
    "    file.close()\n",
    "%timeit loadLinks_byIndex()\n",
    "links_series.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}